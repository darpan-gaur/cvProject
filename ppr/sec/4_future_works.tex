\section{Future Works}
\label{sec:future_works}

We have currently explored key components from multiple research papers to understand both self-supervised learning and explainability techniques. Building on these insights, we will try to develop a hybrid framework that integrates elements from these approaches to obtain explainable representations using self-supervised learning. Our goal is to design a model that not only learns robust representations without labels but also provides meaningful and interpretable visual features.