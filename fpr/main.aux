\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{chen2020simple}
\citation{he2020momentum}
\citation{selvaraju2017grad}
\citation{wickstrom2023relax}
\citation{chen2020simple}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.~Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{\texorpdfstring {\hskip -1em.~}{}Introduction}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.~Problem Statement}{1}{section.2}\protected@file@percent }
\newlabel{sec:problem_statement}{{2}{1}{\texorpdfstring {\hskip -1em.~}{}Problem Statement}{section.2}{}}
\newlabel{sec:problem_statement@cref}{{[section][2][]2}{[1][1][]1}}
\@writefile{brf}{\backcite{chen2020simple}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{he2020momentum}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{selvaraju2017grad}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{wickstrom2023relax}{{1}{2}{section.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.~Literature Review}{1}{section.3}\protected@file@percent }
\newlabel{sec:related_work}{{3}{1}{\texorpdfstring {\hskip -1em.~}{}Literature Review}{section.3}{}}
\newlabel{sec:related_work@cref}{{[section][3][]3}{[1][1][]1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.~Self-supervised Representation Learning}{1}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}\hskip -1em.~SimCLR: Simple Framework for Contrastive Learning of Visual Representations}{1}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{brf}{\backcite{chen2020simple}{{1}{3.1.1}{subsubsection.3.1.1}}}
\citation{caron2020unsupervised}
\citation{he2020momentum}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A simple framework for contrastive learning of visual representations. Two separate data augmentation operators are sampled from the same family of augmentations ($t\sim \mathcal  {T}$ and $t'\sim \mathcal  {T}$) and applied to each data example to obtain two correlated views. A base encoder network $f(\cdot )$ and a projection head $g(\cdot )$ are trained to maximize agreement using a contrastive loss. After training is completed, we throw away the projection head $g(\cdot )$ and use encoder $f(\cdot )$ and representation $\bm  {h}$ for downstream tasks.}}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:framework}{{1}{2}{A simple framework for contrastive learning of visual representations. Two separate data augmentation operators are sampled from the same family of augmentations ($t\sim \mathcal {T}$ and $t'\sim \mathcal {T}$) and applied to each data example to obtain two correlated views. A base encoder network $f(\cdot )$ and a projection head $g(\cdot )$ are trained to maximize agreement using a contrastive loss. After training is completed, we throw away the projection head $g(\cdot )$ and use encoder $f(\cdot )$ and representation $\bm h$ for downstream tasks}{figure.caption.1}{}}
\newlabel{fig:framework@cref}{{[figure][1][]1}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}\hskip -1em.~Learning features by Swapping Assignments between multiple Views (SwAV) of an Image}{2}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{brf}{\backcite{caron2020unsupervised}{{2}{3.1.2}{subsubsection.3.1.2}}}
\newlabel{eq:twoviews}{{1}{2}{\texorpdfstring {\hskip -1em.~}{}Learning features by Swapping Assignments between multiple Views (SwAV) of an Image}{equation.3.1}{}}
\newlabel{eq:twoviews@cref}{{[subsubsection][2][3,1]3.1.2}{[1][2][]2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  We first obtain ``codes'' by assigning features to prototype vectors. We then solve a ``swapped'' prediction problem wherein the codes obtained from one data augmented view are predicted using the other view. Prototype vectors are learned along with the ConvNet parameters by backpropragation. }}{2}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}\hskip -1em.~MoCo: Momentum Contrast for Unsupervised Visual Representation Learning}{2}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{brf}{\backcite{he2020momentum}{{2}{3.1.3}{subsubsection.3.1.3}}}
\newlabel{eq:moco}{{2}{2}{\texorpdfstring {\hskip -1em.~}{}MoCo: Momentum Contrast for Unsupervised Visual Representation Learning}{equation.3.2}{}}
\newlabel{eq:moco@cref}{{[equation][2][]2}{[1][2][]2}}
\citation{Selvaraju_2017_ICCV}
\citation{wickstrøm2022relaxrepresentationlearningexplainability}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Momentum Contrast (MoCo) trains a visual representation encoder by matching an encoded query $q$ to a dictionary of encoded keys using a contrastive loss. The dictionary keys $\{k_0, k_1, k_2, ...\}$ are defined on-the-fly by a set of data samples. The dictionary is built as a queue, with the current mini-batch enqueued and the oldest mini-batch dequeued, decoupling it from the mini-batch size. The keys are encoded by a slowly progressing encoder, driven by a momentum update with the query encoder. This method enables a large and consistent dictionary for learning visual representations. }}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:teaser}{{3}{3}{Momentum Contrast (MoCo) trains a visual representation encoder by matching an encoded query $q$ to a dictionary of encoded keys using a contrastive loss. The dictionary keys $\{k_0, k_1, k_2, ...\}$ are defined on-the-fly by a set of data samples. The dictionary is built as a queue, with the current mini-batch enqueued and the oldest mini-batch dequeued, decoupling it from the mini-batch size. The keys are encoded by a slowly progressing encoder, driven by a momentum update with the query encoder. This method enables a large and consistent dictionary for learning visual representations}{figure.caption.3}{}}
\newlabel{fig:teaser@cref}{{[figure][3][]3}{[1][2][]3}}
\newlabel{eq:infonce}{{3}{3}{\texorpdfstring {\hskip -1em.~}{}MoCo: Momentum Contrast for Unsupervised Visual Representation Learning}{equation.3.3}{}}
\newlabel{eq:infonce@cref}{{[equation][3][]3}{[1][2][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.~Explanibility Techniques}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}\hskip -1em.~Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization}{3}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{brf}{\backcite{Selvaraju_2017_ICCV}{{3}{3.2.1}{subsubsection.3.2.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Grad-CAM visualization of a ResNet-50 model for the class "zebra." The heatmap highlights the regions in the input image that are most relevant for the model's prediction.}}{3}{figure.caption.4}\protected@file@percent }
\newlabel{fig:gradcam}{{4}{3}{Grad-CAM visualization of a ResNet-50 model for the class "zebra." The heatmap highlights the regions in the input image that are most relevant for the model's prediction}{figure.caption.4}{}}
\newlabel{fig:gradcam@cref}{{[figure][4][]4}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}\hskip -1em.~RELAX: Representation Learning Explainability}{3}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{brf}{\backcite{wickstrøm2022relaxrepresentationlearningexplainability}{{3}{3.2.2}{subsubsection.3.2.2}}}
\citation{yarici2024explaining}
\citation{chen2020simple}
\newlabel{eq:sim}{{3.2.2}{4}{\texorpdfstring {\hskip -1em.~}{}RELAX: Representation Learning Explainability}{subsubsection.3.2.2}{}}
\newlabel{eq:sim@cref}{{[subsubsection][2][3,2]3.2.2}{[1][3][]4}}
\newlabel{eq:rel1}{{3.2.2}{4}{\texorpdfstring {\hskip -1em.~}{}RELAX: Representation Learning Explainability}{subsubsection.3.2.2}{}}
\newlabel{eq:rel1@cref}{{[subsubsection][2][3,2]3.2.2}{[1][4][]4}}
\newlabel{eq:rel2}{{3.2.2}{4}{\texorpdfstring {\hskip -1em.~}{}RELAX: Representation Learning Explainability}{subsubsection.3.2.2}{}}
\newlabel{eq:rel2@cref}{{[subsubsection][2][3,2]3.2.2}{[1][4][]4}}
\newlabel{eq:unc1}{{3.2.2}{4}{\texorpdfstring {\hskip -1em.~}{}RELAX: Representation Learning Explainability}{subsubsection.3.2.2}{}}
\newlabel{eq:unc1@cref}{{[subsubsection][2][3,2]3.2.2}{[1][4][]4}}
\newlabel{eq:unc2}{{3.2.2}{4}{\texorpdfstring {\hskip -1em.~}{}RELAX: Representation Learning Explainability}{subsubsection.3.2.2}{}}
\newlabel{eq:unc2@cref}{{[subsubsection][2][3,2]3.2.2}{[1][4][]4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces RELAX explations and uncertainty estimates for a VOC image.}}{4}{figure.caption.5}\protected@file@percent }
\newlabel{fig:relax}{{5}{4}{RELAX explations and uncertainty estimates for a VOC image}{figure.caption.5}{}}
\newlabel{fig:relax@cref}{{[figure][5][]5}{[1][4][]4}}
\@writefile{brf}{\backcite{yarici2024explaining}{{4}{3.2.3}{subsubsection.3.2.3}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}\hskip -1em.~Explaining Representation Learning with Perceptual Components \cite  {yarici2024explaining}}{4}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.~Dataset}{4}{section.4}\protected@file@percent }
\newlabel{sec:dataset}{{4}{4}{\texorpdfstring {\hskip -1em.~}{}Dataset}{section.4}{}}
\newlabel{sec:dataset@cref}{{[section][4][]4}{[1][4][]4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.~Experiments}{4}{section.5}\protected@file@percent }
\newlabel{sec:experiments}{{5}{4}{\texorpdfstring {\hskip -1em.~}{}Experiments}{section.5}{}}
\newlabel{sec:experiments@cref}{{[section][5][]5}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}\hskip -1em.~TSNE plot Visualization}{4}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}\hskip -1em.~Effect of Augmentation on Representation and Explainability}{4}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}\hskip -1em.~GradCAM plots Visualization}{4}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}\hskip -1em.~Perpectual Component Explainability}{4}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}\hskip -1em.~SimClr}{4}{subsection.5.5}\protected@file@percent }
\@writefile{brf}{\backcite{chen2020simple}{{4}{5.5}{subsection.5.5}}}
\citation{wickstrom2023relax}
\bibstyle{ieeenat_fullname}
\bibdata{main}
\bibcite{caron2020unsupervised}{{1}{2020}{{Caron et~al.}}{{Caron, Misra, Mairal, Goyal, Bojanowski, and Joulin}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Loss and Accuracy plot for SimClr}}{5}{figure.caption.6}\protected@file@percent }
\newlabel{fig:loss_accuracy}{{6}{5}{Loss and Accuracy plot for SimClr}{figure.caption.6}{}}
\newlabel{fig:loss_accuracy@cref}{{[figure][6][]6}{[1][5][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}\hskip -1em.~Relax}{5}{subsection.5.6}\protected@file@percent }
\@writefile{brf}{\backcite{wickstrom2023relax}{{5}{5.6}{subsection.5.6}}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces RELAX explanation and uncertanity on CIFAR-10 dataset}}{5}{figure.caption.7}\protected@file@percent }
\newlabel{fig:result1}{{7}{5}{RELAX explanation and uncertanity on CIFAR-10 dataset}{figure.caption.7}{}}
\newlabel{fig:result1@cref}{{[figure][7][]7}{[1][5][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces RELAX explanation and uncertanity on CIFAR-10 dataset}}{5}{figure.caption.8}\protected@file@percent }
\newlabel{fig:result2}{{8}{5}{RELAX explanation and uncertanity on CIFAR-10 dataset}{figure.caption.8}{}}
\newlabel{fig:result2@cref}{{[figure][8][]8}{[1][5][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces RELAX explanation and uncertanity on CIFAR-10 dataset}}{5}{figure.caption.9}\protected@file@percent }
\newlabel{fig:result3}{{9}{5}{RELAX explanation and uncertanity on CIFAR-10 dataset}{figure.caption.9}{}}
\newlabel{fig:result3@cref}{{[figure][9][]9}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.~Observations}{5}{section.6}\protected@file@percent }
\newlabel{sec:observations}{{6}{5}{\texorpdfstring {\hskip -1em.~}{}Observations}{section.6}{}}
\newlabel{sec:observations@cref}{{[section][6][]6}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {7}\hskip -1em.~Code Availability}{5}{section.7}\protected@file@percent }
\newlabel{sec:code_avail}{{7}{5}{\texorpdfstring {\hskip -1em.~}{}Code Availability}{section.7}{}}
\newlabel{sec:code_avail@cref}{{[section][7][]7}{[1][5][]5}}
\bibcite{chen2020simple}{{2}{2020}{{Chen et~al.}}{{Chen, Kornblith, Norouzi, and Hinton}}}
\bibcite{he2020momentum}{{3}{2020}{{He et~al.}}{{He, Fan, Wu, Xie, and Girshick}}}
\bibcite{Selvaraju_2017_ICCV}{{4}{2017{}}{{Selvaraju et~al.}}{{Selvaraju, Cogswell, Das, Vedantam, Parikh, and Batra}}}
\bibcite{selvaraju2017grad}{{5}{2017{}}{{Selvaraju et~al.}}{{Selvaraju, Cogswell, Das, Vedantam, Parikh, and Batra}}}
\bibcite{wickstrom2023relax}{{6}{2023}{{Wickstr{\o }m et~al.}}{{Wickstr{\o }m, Trosten, L{\o }kse, Boubekki, Mikalsen, Kampffmeyer, and Jenssen}}}
\bibcite{wickstrøm2022relaxrepresentationlearningexplainability}{{7}{2022}{{Wickstrøm et~al.}}{{Wickstrøm, Trosten, Løkse, Boubekki, Øyvind Mikalsen, Kampffmeyer, and Jenssen}}}
\bibcite{yarici2024explaining}{{8}{2024}{{Yarici et~al.}}{{Yarici, Kokilepersaud, Prabhushankar, and AlRegib}}}
\gdef \@abspage@last{6}
